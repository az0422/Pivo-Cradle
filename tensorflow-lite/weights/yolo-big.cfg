[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=32
subdivisions=2
width = 416
height = 416
channels=3
momentum=0.9
decay=0.0005
angle=1
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.00261
burn_in=1000

max_batches = 50000
policy=steps
steps=40000, 45000
scales=.1,.1


#weights_reject_freq=1001
#ema_alpha=0.9998
#equidistant_point=1000
#num_sigmas_reject_badlabels=3
#badlabels_rejection_percentage=0.2

#0
[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

#1
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#2
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#3
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

#4
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#5
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#6
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#7
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#8
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#9
[route]
layers=-1, -2, -3, -4, -5

#10
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#11
[maxpool]
size=2
stride=2

#12
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#13
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#14
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#15
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#16
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#17
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#18
[route]
layers=-1, -2, -3, -4, -5

#19
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#20
[maxpool]
size=2
stride=2

#21
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#22
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#23
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#24
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#25
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#26
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#27
[route]
layers=-1, -2, -3, -4, -5

#28
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#11
[maxpool]
size=2
stride=2

#28
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky


##################################

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24
activation=linear



[yolo]
mask = 3,4,5
anchors =  34, 76,  66,172, 163,193, 107,312, 203,358, 335,374
classes=3
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6
#new_coords=1
#scale_x_y = 2.0

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 28

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24
activation=linear

[yolo]
mask = 1,2,3
anchors =  34, 76,  66,172, 163,193, 107,312, 203,358, 335,374
classes=3
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6
#new_coords=1
#scale_x_y = 2.0
